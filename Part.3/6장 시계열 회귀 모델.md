# 6장 시계열 회귀 모델

이번 장에서는 **시계열 회귀 모델**에 대해 소개합니다. 

시계열 회귀 모델은 시간에 따른 데이터를 활용하여 미래의 값을 예측하기 위한 중요한 도구입니다. 일반적인 회귀분석은 독립 변수와 종속 변수 간의 관계를 추정하는 방식으로 이루어지지만, 시계열 데이터에서는 시간 흐름에 따른 변동성, 추세, 그리고 계절성을 고려한 모델링이 필수적입니다. 따라서, 시계열 회귀 모델은 과거 데이터와 시간 의존적인 요인들을 통합하여 종속 변수의 미래 값을 예측하는 데 초점을 맞춥니다.

이 장에서는 전통적인 회귀분석 방법론을 확장하여 시계열 데이터에 적용한 기본적인 회귀분석 예측 방법에 대해 알아볼 예정입니다. 회귀분석은 모델링과 예측을 위한 중요한 도구로, 비교적 간단하면서도 실용적인 방법으로 시계열 데이터를 이해하고 분석하는 데 매우 유용합니다. 이후 회귀분석에 유용한 예측 변수들에 대해 알아볼 것입니다. 변수 선택은 예측 정확도에 큰 영향을 미치며, 특히 시간에 따라 변화하는 특성을 반영하는 것이 중요합니다. 마지막으로 추세와 계절성을 모델링하는 방법을 다룰 예정입니다.

[TOC]

<div style="page-break-after: always; break-after: page;"></div>

## 6.1 회귀분석 예측

이번 소단원에서는 **회귀분석 예측**에 대해 다룹니다.

시계열 회귀분석은 시간에 따른 데이터를 예측하는데 회귀분석을 활용하는 방법으로, 고전적인 시계열 분해와 달리 미래의 시계열 값을 직접 예측하는 데 적합합니다. 고전적인 시계열 분해는 과거의 데이터를 효과적으로 분석하는 데 유용하지만, 미래 예측에는 한계가 있습니다. 간단한 예측 방법으로 나이브, 계절적 나이브, 평균 방법 등을 사용할 수 있지만, 이러한 방법들은 추세와 계절성 정보를 충분히 반영하지 못하는 단점이 있습니다. 이와 달리 회귀분석은 과거 관측값뿐만 아니라 추세, 계절성 등의 시간 의존적 특성을 변수로 활용하여 보다 정교한 예측을 가능하게 합니다.



### 6.1.1. 간단한 예측 방법

시계열 예측에서는 여러 간단한 예측 방법들이 존재하며, 이를 통해 빠르고 직관적인 예측을 수행할 수 있습니다. 이 방법들은 빠르게 예측을 수행할 수 있지만, 추세나 계절성 같은 시계열의 복잡한 패턴을 충분히 반영하지 못할 수 있습니다. 이 방법들은 과거 데이터 $y_{1}, y_{2}, ..., y_{T}$를 바탕으로 향후 예측 기간 $h$ 동안의 모든 시간 단계에 대한 예측치 $\hat{y}_{T+1}, \hat{y}_{T+2}, ..., \hat{y}_{T+h}$를 간단하게 출력할 수 있습니다.



#### 1) 나이브 방법

**나이브 방법(Naive Method)**은 가장 최근에 관측된 값을 그대로 미래의 예측값으로 사용하는 기법입니다. 즉, 현재까지의 관측값 $y_1, y_2, ..., y_T$ 중에서 마지막 값 $y_T$가 미래에도 유지될 것이라고 가정하여 미래의 예측값 $\hat{y}_{T+t}$를 $y_T$로 고정합니다. 수식으로는 다음과 같이 표현됩니다:
$$
\hat{y}_{T+t}=y_T, \quad t=1,..., h
$$

이 방법은 데이터를 추가적으로 처리할 필요 없이 바로 예측이 가능하지만, 추세나 계절성 정보를 반영하지 않기 때문에 예측의 정확도는 떨어질 수 있습니다.



#### 2) 계절적 나이브 방법

**계절적 나이브 방법(Naive Seasonal Method)**은 나이브 방법에서 한 걸음 더 나아가, 계절성을 반영한 예측을 수행합니다. 미래의 예측값을 가장 최근에 관찰된 시즌의 동일한 시점 값으로 설정합니다. 예를 들어, 월별 데이터에서 1월 데이터를 예측할 때 과거의 1월 데이터를 활용하는 방식입니다. 계절 주기를 $s$로 할 때, 계절적 나이브 방법은 다음과 같이 표현됩니다:
$$
\hat{y}_{T+t}=y_{T+t- \lfloor t/s \rfloor s}, \quad t=1,..., h
$$

이 방법은 계절 패턴을 반영하므로, 계절적인 반복 패턴이 뚜렷한 시계열 데이터를 예측하는 데 유용합니다. 예를 들어, 월별 판매량이나 기후 데이터를 예측할 때 적합합니다. 그러나 계절성 외에 다른 추세가 존재할 경우 그 정보를 반영하지 못하는 한계가 있습니다.



#### 3) 평균 방법

**평균 방법(Mean Method)**은 과거의 모든 관측값을 평균 내어 미래 값을 예측하는 방법입니다. 과거의 관측값들이 모두 일정한 중요성을 가진다고 가정하고, 그 평균을 예측값으로 사용합니다. 수식은 다음과 같습니다:
$$
\hat{y}_{T+t}=\frac{1}{T} \Sigma_{t=1}^T y_t, \quad t=1,..., h
$$

평균 방법은 나이브 방법보다 약간 더 복잡하지만, 여전히 비교적 단순한 방법입니다. 이 방법은 과거 데이터가 큰 변동 없이 일정한 패턴을 보일 때 유용합니다. 그러나 이 역시 추세나 계절성과 같은 중요한 패턴을 반영하지 못하기 때문에, 복잡한 시계열 데이터에는 부적합할 수 있습니다.

이러한 간단한 예측 방법들은 빠르고 직관적으로 사용할 수 있는 장점이 있지만, 시계열 데이터에서 발생하는 더 복잡한 구조적 패턴을 반영하지 못하므로 더 정교한 예측 방법들과 비교했을 때 정확도가 떨어질 수 있습니다.

------

**예제 6-1. 간단한 예측 방법 예시** 

**호주 생산량 데이터 예측** <span style="color:red">(데이터, 그래프, 설명 변경 필요)</span>

다음 그래프들은 호주 생산량 데이터를 각 방법으로 예측한 값을 시각화한 그래프입니다.

![naive](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-1.naive.png?raw=true)

[그림 6-1. 호주 생산량 데이터를 나이브, 계절적 나이브, 평균 방법으로 예측한 결과]



위 그래프들은 "간단한 예측 방법"을 보여주는 세 가지 기법인 나이브 방법, 계절적 나이브 방법, 그리고 평균 방법을 시각적으로 나타낸 것입니다. 각 방법은 관측된 과거 데이터를 기반으로 향후 데이터를 예측하는 기본적인 기법입니다. 위 그래프의 가로축은 1950년부터 2000년대 초반까지의 데이터를 포함하고 있으며,  세로축은 호주의 생산량 수를 표시합니다. 검은색 선은 실제 관측된 데이터를 나타내고, 파란색 선은 예측된 값입니다. 

가장 왼쪽 그래프는 나이브 방법으로 예측한 그래프입니다. 이 방법은 미래 예측값이 현재의 마지막 관측값과 동일하다는 단순한 가정을 기반으로 합니다. 따라서, 예측된 값이 일정하게 수평으로 이어지는 모습을 볼 수 있습니다. 이 방법은 데이터에 명확한 추세가 없는 경우에는 유용할 수 있지만, 추세나 계절성이 있는 데이터에는 적합하지 않습니다. 가운데 그래프는 계절적 나이브 방법으로 예측한 그래프입니다. 이 방법에서는 미래의 예측값을 이전 계절 주기 때의 값으로 설정합니다. 계절성이 명확한 데이터에 더 적합하며, 데이터의 계절적 패턴을 반영한 예측을 할 수 있습니다. 그래프에서 볼 수 있듯이, 예측된 값이 이전의 계절적 패턴과 일치하는 것을 확인할 수 있습니다. 가장 오른쪽 그래프는 평균 방법으로 예측한 그래프입니다. 미래의 모든 예측값이 과거 데이터의 평균 값으로 설정됩니다. 이 방법은 데이터가 불규칙하게 변동하거나 분명한 패턴을 따르지 않을 때 유용할 수 있습니다. 하지만 추세나 계절성을 반영하지 않기 때문에, 그래프에서 볼 수 있듯이 예측된 값이 일정하게 나타나며, 이는 추세가 있는 데이터에서는 비효율적일 수 있습니다.

아래는 위 그래프를 구현하기 위한 코드입니다.

```python
#필요한 패키지 불러오기
import pandas as pd
import matplotlib.pyplot as plt


#데이터 전처리
def parse_quarter_string(q):
    """
    Converts a quarter string 'YYYY Qq' to a datetime object.
    """
    year, quarter = q.split(' Q')
    first_month_of_quarter = 3 * int(quarter) - 2
    return f"{year}-{first_month_of_quarter}-01"

aus_production = pd.read_csv('https://raw.githubusercontent.com/safeai-snu/Econometrics/refs/heads/main/Part.3/data/aus_production.csv')
aus_production['Quarter'] = aus_production['Quarter'].apply(parse_quarter_string)
aus_production['Quarter'] = pd.to_datetime(aus_production['Quarter'])
aus_production.set_index('Quarter', inplace=True)


#Naive forecasting
aus_production['Naive'] = aus_production['Bricks'].shift(1)


#Naive seasonal forecasting
seasonality = 4
aus_production['Naive_Seasonal'] = aus_production['Bricks'].shift(seasonality)


#Mean method
aus_production['Mean'] = aus_production['Bricks'].expanding().mean()


#예측
forecast_start = '2000-01-01'
naive_mask = (aus_production.index >= forecast_start)
naive_seasonal_mask = (aus_production.index >= forecast_start)
mean_mask = (aus_production.index >= forecast_start)


#시각화
plt.figure(figsize=(20,6))

plt.subplot(131)
plt.plot(aus_production['Bricks'], label='Actual', color='black')
plt.plot(aus_production.index[naive_mask], aus_production['Naive'][naive_mask], label='Naive Forecast', color='blue')
plt.title('Naive Method')
plt.legend()

plt.subplot(132)
plt.plot(aus_production['Bricks'], label='Actual', color='black')
plt.plot(aus_production.index[naive_seasonal_mask], aus_production['Naive_Seasonal'][naive_seasonal_mask], label='Naive Seasonal Forecast', color='blue')
plt.title('Naive Seasonal Method')
plt.legend()

plt.subplot(133)
plt.plot(aus_production['Bricks'], label='Actual', color='black')
plt.plot(aus_production.index[mean_mask], aus_production['Mean'][mean_mask], label='Mean Forecast', color='blue')
plt.title('Mean Method')
plt.legend()

plt.tight_layout()
plt.show()
```

------



### 6.1.2. 선형 회귀 예측

선형 회귀분석은 시계열 예측에서 간단한 방법들을 보완해 주는 강력한 도구입니다. 선형 회귀는 과거 데이터를 이용해 미래 값을 예측하는 과정에서 여러 독립 변수를 사용하여 종속 변수를 설명합니다. 이때 미래 예측값 $\hat{y_t}$는 여러 독립 변수들의 가중 조합으로 표현되며, 목표는 실제 값 $y_t$에 가장 가까운 예측값을 만드는 것입니다.

선형 회귀 모델은 다음과 같이 표현됩니다.

$$
\hat{y}_t = \sum_{d=1}^{D} w_d x_{t,d}
$$

여기서 $x_{t,d}$는 입력 변수로, 과거 관측값, 추세 변수, 계절성 변수, 목표 변수의 지연값 등이 될 수 있습니다. $w_d$는 각 변수에 할당된 가중치입니다. 목표는 가중치 $w_d$들을 적절히 선택하여 예측값 $\hat{y}_t$가 실제 값 $y_t$에 최대한 근접하도록 하는 것입니다.

이때 가중치 $w_d$는 최소자승법(Least Squares Method)을 통해 결정됩니다. 최소자승법은 다음과 같이 잔차(실제값과 예측값의 차이)의 제곱합을 최소화하는 방식으로 가중치를 찾습니다:

$$
w^{*} = \arg \min_w \sum_{t=1}^{T} (y_t - \hat{y}_t)^2 = \sum_{t=1}^{T} (y_t - \sum_{d=1}^{D} w_d x_{t,d})^2
$$

이 과정을 통해 최적의 가중치 $w^{*}$을 구하면, 이를 사용하여 미래의 값을 예측할 수 있습니다. 예측 모델은 다음과 같이 표현됩니다:

$$
\hat{y}_{t} = \sum_{d=1}^{D} w_d^* x_{t,d}, \quad t = T+1, T+2, ..., T+h
$$

선형 회귀는 과거의 다양한 패턴을 변수로 활용하여 단순한 나이브 방법이나 평균 방법보다 복잡한 데이터의 미래 값을 더 정확하게 예측할 수 있습니다. 특히, 선형 회귀 모델은 독립 변수로 추세와 계절성, 목표 변수의 지연값 등을 포함함으로써 데이터의 복잡한 패턴을 학습하고, 이를 바탕으로 보다 정확한 미래 예측을 제공합니다. 선형 회귀를 통한 예측은 단순 예측 방법보다 복잡하지만, 시계열 데이터의 특성을 잘 반영할 수 있으며, 다양한 예측 변수들과 가중치 학습을 통해 더욱 정교한 예측 결과를 얻을 수 있는 장점이 있습니다.

------

**예제 6-2. 선형 회귀 예시** 

**호주 생산량 데이터 선형 회귀** <span style="color:red">(데이터, 그래프, 설명 변경 필요)</span>

다음 그래프는 선형 회귀를 이용하여 호주 생산량 데이터를 예측한 그래프입니다.

![linreg](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-2.linreg.png?raw=true)

[그림 6-2. 호주 생산량 데이터를 선형 회귀로 예측한 결과]



위 그래프의 가로축은 1950년부터 2010년까지의 기간을 나타내며, 세로축은 벽돌 생산량을 나타내며, 대략 200에서 600 사이의 범위에 걸쳐 있습니다. 최대값은 1980년대 초반, 약 550 정도의 값을 나타내고, 최소값은 1950년대 초반, 약 200 정도의 값에서 시작합니다. 검은색 선은 실제 데이터로 장기적인 상승 추세를 보이면서도 중간에 큰 변동성(특히 1980년대의 급격한 하락과 회복)이 존재합니다. 빨간색 점선은 선형 회귀 모델을 사용하여 예측한 결과입니다. 이 모델은 시간에 따른 데이터의 전반적인 경향(추세)을 직선으로 나타내며, 장기적인 상승 추세를 반영하고 있습니다. 선형회귀는 시간이 지남에 따라 값이 꾸준히 상승할 것이라고 예측하고 있습니다. 이는 추세에 초점을 맞추고 있지만, 데이터의 변동성을 충분히 반영하지는 못하고 있습니다.

이처럼 선형 회귀는 전체적인 경향(추세)만을 반영하기 때문에, 단기적인 변동이나 계절성과 같은 복잡한 패턴을 설명하지 못합니다. 예를 들어, 데이터에서 1980년대와 같은 큰 변동성을 반영하지 못하고, 장기적인 평균적인 상승 경향을 직선으로 표현합니다. 따라서, 변동성이 큰 시계열 데이터에 대해서는 선형 회귀만으로는 적합한 예측을 제공하기 어려울 수 있습니다. 이 경우, 추세와 계절성, 주기적 패턴 등을 고려하는 복잡한 모델이 필요할 수 있습니다.

아래는 위 그래프를 구현하기 위한 코드입니다.

```python
#필요한 패키지 불러오기
import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt


#데이터 전처리
aus_production = pd.read_csv('https://raw.githubusercontent.com/safeai-snu/Econometrics/refs/heads/main/Part.3/data/aus_production.csv')
aus_production['Quarter'] = aus_production['Quarter'].apply(parse_quarter_string)
aus_production['Quarter'] = pd.to_datetime(aus_production['Quarter'])
aus_production.set_index('Quarter', inplace=True)
aus_production['Time_Index'] = np.arange(len(aus_production))


#선형 회귀 모델
X = sm.add_constant(aus_production['Time_Index'])
y = aus_production['Bricks']

model = sm.OLS(y, X, missing='drop').fit()  

aus_production['Linear_Forecast'] = model.predict(X)


#시각화
plt.figure(figsize=(12, 6))
plt.plot(aus_production['Bricks'], label='Actual', color='black')
plt.plot(aus_production['Linear_Forecast'], label='Linear Forecast', color='red', linestyle='--')
plt.title('Linear Regression Forecast')
plt.xlabel('Quarter')
plt.ylabel('Bricks')
plt.legend()
plt.show()
```

------



### 6.1.3. 선형 회귀 변수 선택

회귀분석에서 변수 선택은 매우 중요한 요소입니다. 변수들은 과거의 시계열 데이터에서 유의미한 패턴을 반영하며, 미래 예측에 큰 영향을 미칩니다. 이러한 변수들은 데이터의 추세, 계절성, 지연값 등을 포함해 시계열의 구조적인 특성을 포착할 수 있는 다양한 정보를 제공합니다. 시계열 회귀분석에서 주로 사용하는 변수들은 다음과 같습니다.

**추세 변수**

추세 변수는 데이터의 장기적인 변화를 나타내며, 데이터의 방향성과 관련된 정보를 제공합니다. 이 변수는 선형, 로그, 지수, 로지스틱 함수 등의 형태로 표현될 수 있으며, 주로 시간이 지남에 따라 발생하는 전반적인 상승 또는 하강 추세를 반영합니다. 추세 변수는 예측에서 기본적인 흐름을 잡아주는 역할을 합니다.

**계절성 변수**

계절성 변수는 데이터에서 주기적으로 반복되는 패턴을 포착하는 데 사용됩니다. 예를 들어, 특정 시점에 반복적으로 나타나는 월별, 주별, 연간 패턴을 반영할 수 있습니다. 이를 구현하는 방법으로는 더미 변수(One-hot Encoding) 또는 푸리에 변환, 웨이블릿 변환 같은 주기적 변환을 사용할 수 있습니다. 이러한 변수들은 시간에 따른 반복적 특성을 예측하는 데 필수적입니다.

**목표 변수의 지연값**

지연값은 과거의 데이터를 활용해 미래의 값을 예측하는 기본적인 방법 중 하나입니다. 예를 들어, $y_{t-1}$, $y_{t-2}$와 같은 이전 시간 단계의 값을 입력 변수로 사용하여 현재의 $y_t$를 예측할 수 있습니다. 이는 시계열 데이터에서 자기상관 관계(Autocorrelation)가 존재할 때 특히 유용합니다.

**목표 변수의 계절적 지연 값**

계절적 지연값은 특정 계절의 과거 값을 사용하여 미래 계절의 값을 예측하는 방식입니다. 예를 들어, 이전 연도나 이전 달의 같은 시점에서의 값이 미래의 동일 시점 값을 예측하는 데 유용할 수 있습니다. 이는 계절적 패턴이 강한 데이터에서 중요한 예측 변수가 될 수 있습니다.

**(가중) 평균**

과거의 관측값들의 평균 또는 가중 평균을 사용해 예측에 활용할 수 있습니다. 예를 들어, 최근 7일간의 데이터를 평균내어 $\text{mean}(y_{t-1:t-7})$과 같은 변수로 사용할 수 있습니다. 이는 과거의 특정 구간에서 얻은 정보를 기반으로 미래 값을 예측하는 방식입니다.


이와 같은 변수들은 시계열 데이터를 설명하고 미래를 예측하는 데 중요한 역할을 합니다. 추세 변수와 계절성 변수는 외생(Exogenous) 변수로, 즉 시계열 외부에서 오는 정보로 간주됩니다. 반면, 목표 변수의 지연값과 (가중) 평균은 내생(Endogenous) 변수로, 시계열 자체의 과거 값을 이용해 현재를 설명하는 변수들입니다. 목표 변수의 계절적 지연값과 (가중) 평균은 목표 변수의 지연값의 특별한 경우로 볼 수 있습니다. 이를 통해 계절성 등 도메인 지식을 활용한 변수 설계를 통해 더 적은 매개변수로도 동일한 효과를 얻을 수 있습니다.



### 6.1.4. 확률적 모델로서의 선형 회귀

#### 1) 선형 회귀의 확률적 모델로 확장
시계열 회귀분석에서 확률적 모델로의 확장은 데이터의 불확실성을 반영하여 예측 성능을 향상시키기 위한 중요한 과정입니다. 전통적인 선형 회귀는 잔차의 제곱합을 최소화하는 방식으로 가중치를 학습하지만, 이는 잔차가 정규 분포를 따른다는 가정에 기반합니다. 이때 잔차의 제곱을 최소화하는 것은 사실상 잔차의 확률을 최대화하는 것과 같기 때문에, 이 과정을 확률적 모델로 해석할 수 있습니다.

선형 회귀에서는 최대 우도 추정(Maximum Likelihood Estimation, MLE)을 통해 가중치를 추정하게 됩니다. 이를 통해 회귀 분석이 확률적 기반으로 이루어지며, 예측 불확실성을 반영하는 방식으로 변환됩니다. 먼저, 관측된 데이터 $y_t$는 잠재적(미관측) 변수 $z_t$와 잡음(오차) $\varepsilon_t$의 합으로 표현됩니다. 이를 수식으로 표현하면 다음과 같습니다:

$$
y_t = z_t + \varepsilon_t
$$

여기서 $z_t$는 예측하고자 하는 값이며, $z_t = \sum_{d=1}^{D} w_d x_{t,d}$와 같이 여러 변수들의 가중 조합으로 나타냅니다. 오차 $\varepsilon_t$는 $N(0, \sigma^2)$로 가정되며, 가우시안 분포를 따르는 랜덤 변동성을 나타냅니다. 이러한 확률적 모델을 수학적으로 표현하면 다음과 같습니다:

$$
P(y_t | x_t) = N(\sum_{d=1}^D w_d x_{t,d}, \sigma^2)
$$

즉, 관측된 값 $y_t$는 주어진 변수 $x_t$의 가중 조합 $\sum_{d=1}^D w_d x_{t,d}$을 평균으로 하고, 분산이 $\sigma^2$인 정규 분포에서 생성된 값으로 해석됩니다. 이러한 확률적 해석을 통해 우리는 모델이 잔차(오차)를 최소화하는 방식으로 학습되며, 그 해는 최대 우도 추정(Maximum Likelihood Estimation, MLE)에 의해 가중치 $w^{*} $를 찾는 과정과 동치입니다. MLE를 통해 최적의 가중치는 다음과 같이 구할 수 있습니다:

$$
w^{*} = \arg \max_w P(y_{1:t} | x_{1:t}) = \arg \max_w \sum_{t=1}^T \ln P(y_t | x_t)
$$

이를 전개하면, 최종적으로 다음과 같은 식으로 표현됩니다:

$$
w^{*} = \arg \min_w \sum_{t=1}^T \left(-\ln \sqrt{2\pi\sigma^2} - \frac{(y_t - \sum_{d=1}^D w_d x_{t,d})^2}{2\sigma^2}\right)  = \arg \min_w \sum_{t=1}^T (y_t - \sum_{d=1}^D w_d x_{t,d})^2
$$

$$
\min_w \sum_t e_t^2 \text{ with } e_t = y_t - \hat{y_t}
\Longleftrightarrow \max \prod_t P(e_t) \text{ with } e_t \sim \mathcal{N}(0, \sigma^2)
$$
즉, 잔차의 제곱을 최소화하는 것이 최대 우도 추정(MLE)과 동치임을 확인할 수 있습니다.



#### 2) 일반화 선형 모델

선형 회귀는 잔차가 정규 분포를 따른다는 가정을 기반으로 하지만, 실제 잔차는 다양한 분포를 가질 수 있습니다. **일반화 선형 모델(Generalized Linear Model, GLM)**은 이러한 문제를 해결하기 위한 확장된 모델로, 잔차의 가우시안 가정이 적합하지 않은 경우, 일반화 선형 모델(GLM)을 통해 다양한 확률 분포를 활용할 수 있습니다. GLM에서는 잔차가 가우시안 분포 이외의 다양한 분포를 따를 수 있으며, 다양한 데이터 특성을 반영할 수 있습니다.

GLM에서는 관측된 데이터 $y_t$가 주어진 입력 변수 $x_t$에 따라 특정 분포 $P(y_t | x_t)$를 따르는 것을 가정하며, 이러한 분포는 데이터의 성격에 따라 적절히 선택됩니다. 여러 가지 대표적인 분포는 다음과 같습니다:


* **포아송 분포**

횟수형 데이터(Count Data)에 적합하며, 자연스럽게 비음수 정수값을 모델링할 수 있습니다. 예를 들어, 하루에 발생하는 사건의 횟수나 판매 건수 등을 설명할 수 있습니다. 포아송 분포의 확률 질량 함수(PMF)는 다음과 같습니다:
$$
P(y | \lambda) = \frac{\lambda^y e^{-\lambda}}{y!}, \quad y = 0, 1, 2, \dots
$$
여기서 $\lambda > 0$은 평균과 분산을 모두 나타냅니다.


* **음이항 분포**

포아송 분포와 비슷하지만, 분산이 더 큰 데이터에 적용됩니다. 즉, 변동성이 크고 과도한 분산을 가진 횟수형 데이터를 모델링하는 데 적합합니다. 음이항 분포의 확률 질량 함수(PMF)는 다음과 같습니다:
$$
P(y | r, p) = \binom{y + r - 1}{y} p^r (1-p)^y, \quad y = 0, 1, 2, \dots
$$
여기서 $r > 0$은 성공 횟수, $p \in (0, 1)$은 성공 확률을 나타냅니다.


* **베타 분포**

베타 분포는 0과 1 사이의 연속적인 값에 대해 예측을 할 때 사용됩니다. 예를 들어, 비율이나 확률 같은 데이터를 설명할 수 있습니다. 베타 분포의 확률 밀도 함수(PDF)는 다음과 같습니다:
$$
P(y | \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} y^{\alpha - 1} (1-y)^{\beta - 1}, \quad 0 \leq y \leq 1
$$
여기서 $\alpha > 0$과 $\beta > 0$은 형태 매개변수입니다.


* **베르누이 분포**

이진 데이터에 적합합니다. 예를 들어, 사건이 발생하거나 발생하지 않는 경우와 같은 상황에서, GLM은 베르누이 분포를 통해 이진 결과를 예측할 수 있습니다. 베르누이 분포의 확률 질량 함수(PMF)는 다음과 같습니다:
$$
P(y | p) = p^y (1-p)^{1-y}, \quad y \in \{0, 1\}, \quad 0 \leq p \leq 1
$$
여기서 $p$는 사건이 발생할 확률입니다.


* **스튜던트-t 분포**

긴 꼬리(Long-Tail)를 가지는 데이터에 적합하며, 극단값(이상값)에 대해 보다 강건한 예측을 제공합니다. 금융 시장의 가격 변동 같은 비정상적인 데이터에 효과적입니다. 스튜던트-t 분포의 확률 밀도 함수(PDF)는 다음과 같습니다:
$$
P(y | \nu) = \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi} \Gamma\left(\frac{\nu}{2}\right)} \left(1 + \frac{y^2}{\nu}\right)^{-\frac{\nu+1}{2}}
$$
여기서 $\nu > 0$은 자유도를 나타내며, $\Gamma$는 감마 함수입니다.


GLM을 통해 데이터의 특성에 맞춘 적절한 확률 분포를 선택함으로써, 선형 회귀보다 더 넓은 범위의 데이터 유형을 설명할 수 있습니다. 이러한 유연성은 다양한 실제 데이터의 특성을 더 잘 반영할 수 있으며, 각기 다른 분포를 통해 예측 모델의 성능을 향상시킬 수 있습니다. GLM은 데이터에 대한 고정된 가정 없이, 각 데이터의 본질적인 특성에 따라 모델링할 수 있는 강력한 도구로, 예측 정확도를 높이고 다양한 데이터 유형에 대응할 수 있는 능력을 제공합니다.



### 6.1.5. 예측 분포와 예측 구간

시계열 회귀 분석에서는 예측된 값뿐만 아니라 예측의 불확실성까지 반영할 수 있는 **예측 구간(Prediction Intervals)**을 제시하는 것이 중요합니다. 예측 구간은 예측값이 특정 범위 내에 있을 확률을 나타내며, 예측 구간이 넓을수록 미래의 불확실성이 커진다는 것을 의미합니다. 이를 통해 예측의 신뢰성을 높일 수 있습니다. 일반적으로 예측 기간이 길어질수록 예측 구간은 넓어지며, 이는 미래의 불확실성이 증가한다는 점을 반영합니다. 특히, 가우시안 분포 가정을 사용할 경우, 예측 구간은 예측값의 불확실성을 반영하여 계산되며 예측값의 95% 신뢰 구간은 다음과 같이 계산될 수 있습니다:
$$
\hat{y}_{T+h |T} \pm 1.96 \hat{ \sigma}_h
$$


이때, 점 예측은 불확실성을 반영하지 않은 단일 값이기 때문에 신뢰도가 낮을 수 있습니다. 따라서 예측 구간을 함께 제공함으로써, 예측의 정확성과 신뢰도를 높일 수 있습니다. 예측 구간을 계산할 때는 모델이 확률적이어야 하며, 무작위 오류(랜덤 노이즈)를 반영해야 합니다. 일반적으로, 예측을 신뢰하기 위해서는 잔차의 가정을 확인해야 합니다. 잔차 가정이 맞지 않으면 예측 구간이 너무 좁아지거나 부정확해질 수 있습니다.



#### 1) 기준 방법

다양한 기준 방법(Benchmark Method)들을 통해 간단한 예측 구간을 계산할 수 있습니다:


* **평균(Mean)**

과거의 모든 관측값의 평균을 사용하여 예측값을 계산합니다. 즉, $\hat{y}_{T+h|T} = \frac{1}{T} \Sigma_{t=1}^T y_t$ 입니다. 이 방법의 예측 구간은 예측 기간에 비례하지 않으며, 분산도 일정하게 유지됩니다. 즉, $\hat{\sigma}_h = \hat{\sigma} \sqrt{1 + \frac{1}{T}}$을 만족합니다.


* **나이브(Naïve)**

가장 최근의 관측값을 그대로 예측값으로 사용합니다.즉, $\hat{y}_{T+h|T} = y_T$ 입니다. 나이브 방법의 예측 구간은 예측 기간이 길어짐에 따라 선형적으로 증가합니다. 즉, $\hat{\sigma}_h = \hat{\sigma} \sqrt{h}$을 따릅니다.


* **계절적 나이브(Seasonal Naïve)**

과거의 계절성을 반영하여, 동일한 계절 주기에 해당하는 과거 값을 사용합니다. 즉, $\hat{y}_{T+h|T} = y_s$ where $s = T+h-m(k+1)$ 입니다. 이 방법 역시 계절에 따른 예측 구간을 계산합니다. $\hat{\sigma}_h = \hat{\sigma} \sqrt{k + 1}$.


* **드리프트(Drift)**

관측값의 증가 또는 감소 추세를 반영하여 예측합니다. 즉, $\hat{y}_{T+h|T} = y_T  + \frac{h}{T-1} \Sigma_{t=1}^Te_t$ 입니다. 여기서 $e_t = y_t - y_{t-1}$는 각 시간 단계에서의 차이입니다. 이때 분산은 다음과 같습니다. $\hat{\sigma}_h = \hat{\sigma} \sqrt{h \left(1 + \frac{h}{T - 1}\right)}$.



#### 2) 부트스트랩 잔차를 이용한 예측 구간

부트스트랩(Bootstrap) 기법을 사용하면, 잔차로부터 무작위로 값을 추출하여 예측 구간을 생성할 수 있습니다. 한 단계 앞 예측 오류 $e_t$는 다음과 같이 정의됩니다:
$$
e_t = y_t - \hat{y}_{t|t-1}
$$
예를 들어, 나이브 방법을 적용한다면, $\hat{y}_{t|t-1} = y_{t-1}$이 되고 다음과 같은 예측을 할 수 있습니다:
- $\hat{y}_{t+1} = y_t + e_{t+1}$, 여기서 $e_{t+1}$은 과거 잔차에서 무작위로 추출된 값입니다.
- $\hat{y}_{t+2} = \hat{y}_{t+1} + e_{t+2}$, 여기서 $e_{t+2}$는 또 다른 무작위 추출된 잔차입니다.

이런 방식으로, 시계열의 전체 미래 값을 시뮬레이션하여 다양한 예측 시나리오를 생성할 수 있습니다. 부트스트랩 방법은 다양한 잔차 분포를 반영할 수 있어, 보다 유연한 예측 구간을 제공합니다. 이러한 예측 구간의 계산은 시계열 예측에서 매우 중요한 역할을 하며, 특히 불확실성이 큰 데이터를 다룰 때 더욱 신뢰성 있는 결과를 얻을 수 있습니다.

------

**예제 6-3. 부트스트랩 예시** 

**애플 주가 데이터 부트스트랩** 

다음 그래프들은 애플의 주가 데이터를 부트스트랩 잔차를 이용하여 예측한 결과를 시각화한 그래프입니다. 

![boot](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-3.bootstrap.png?raw=true)
![boot_pi](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-3.boot_pi.png?raw=true)

[그림 6-3. 애플 주가 데이터 부트스트랩 잔차로 예측한 결과 시뮬레이션]



위 그래프들의 가로축은 2018년 1월부터 2023년 12월까지의 시간(일 단위)을 나타내며, 세로축은 애플의 주가를 달러 단위로 표시합니다. 첫 번째 그래프는 **나이브 방법을 적용하여 예측을 시뮬레이션한 결과**를 보여주고 있습니다. 주가의 실제 값은 짙은 파란색 선으로 나타내며,로, 예측된 잔차들이 회색 선으로 여러 개 시뮬레이션된 형태로 나타납니다. 예측 값은 과거 잔차에서 무작위로 추출된 값을 바탕으로 한 **미래 예측 값들**로, 실제 데이터가 없는 미래 구간에 대해서 다양한 변동성을 반영한 여러 개의 예측 경로가 제공됨으로써 예측의 불확실성을 효과적으로 보여줍니다.

두 번째 그래프는 **예측 구간을 표시한 그래프**입니다. 여기서 예측 구간은 **80%와 95% 신뢰 구간**으로 표시되어 있으며, 예측된 미래 주가 값들이 이 범위 내에 존재할 확률이 각각 80%와 95%라는 것을 의미합니다. 예측 구간은 그래프에서 색깔로 구분되며, 95% 구간은 넓은 범위로, 80% 구간은 좁은 범위로 나타나 있습니다. 이는 예측된 값이 더 높은 신뢰도에서 예측 범위가 좁아지고, 낮은 신뢰도에서는 예측 범위가 넓어지기 때문입니다.

이 부트스트랩 방식은 **잔차의 분포**를 고려하여 예측 구간을 생성하는 방법이기 때문에, 불확실성이나 예측의 변동성을 반영할 수 있습니다. 특히 주식 시장처럼 **변동성이 큰 데이터**에 대해서 부트스트랩은 매우 유용하게 활용됩니다.

아래는 위 그래프를 구현하기 위한 코드입니다.

```python
#필요한 패키지 불러오기
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


#애플(AAPL) 주식 데이터 가져오기
ticker = "AAPL"
start_date = "2018-01-01"
end_date = "2023-12-31"


#주식 데이터 다운로드
tick = yf.Ticker(ticker)
stock = tick.history(start=start_date, end=end_date)


#종가 데이터 추출
stock = stock[['Close']]
stock['Naive_Forecast'] = stock['Close'].shift(1)
stock['Residuals'] = stock['Close'].diff(1)


#부트스트랩
np.random.seed(0)  
n_days = 100
n_simulations = 100  
last_value = stock['Close'].iloc[-1]

simulations = pd.DataFrame(index=range(n_days), columns=range(n_simulations))

for sim in range(n_simulations):
    simulated_values = [last_value]
    for day in range(1, n_days):
        simulated_values.append(simulated_values[day-1] + np.random.choice(stock['Residuals'].dropna()))
    simulations[sim] = simulated_values

percentiles = [80, 95]
lower_bounds = simulations.quantile(q=(1-percentiles[0]/100)/2, axis=1)
upper_bounds = simulations.quantile(q=1-(1-percentiles[0]/100)/2, axis=1)
lower_bounds_95 = simulations.quantile(q=(1-percentiles[1]/100)/2, axis=1)
upper_bounds_95 = simulations.quantile(q=1-(1-percentiles[1]/100)/2, axis=1)


#시각화
plt.figure(figsize=(14, 7))
plt.plot(stock.index, stock['Close'], label='Actual')
for sim in simulations.columns:
    plt.plot(stock.index[-1] + pd.to_timedelta(range(n_days), unit='D'), simulations[sim], alpha=0.1, color='grey')
plt.title('Apple Stock Price Simulation using Naive Method with Bootstrapped Residuals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

plt.figure(figsize=(14, 7))
plt.plot(stock.index, stock['Close'], label='Actual')
plt.fill_between(stock.index[-1] + pd.to_timedelta(range(n_days), unit='D'), lower_bounds, upper_bounds, color='blue', alpha=0.1, label=f'{percentiles[0]}% Interval')
plt.fill_between(stock.index[-1] + pd.to_timedelta(range(n_days), unit='D'), lower_bounds_95, upper_bounds_95, color='blue', alpha=0.2, label=f'{percentiles[1]}% Interval')
plt.title('Apple Stock Price Forecast Intervals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()
```

------



## 6.2 유용한 예측 변수

시계열 분석에서 유용한 예측 변수를 선정하는 것은 예측 모델의 성능을 크게 좌우하는 중요한 단계입니다. 시계열 데이터는 시간에 따라 변화하는 패턴을 가지기 때문에, 이러한 패턴을 잘 반영한 변수를 선정하는 것이 필수적입니다. 이때 변수 변환을 통해 내재적 선형성을 부여하거나, 주기적 특성을 조화 회귀를 통해 처리하는 방법이 자주 사용됩니다. 이 소단원에서는 내재적 선형 모델과 조화 회귀의 주요 개념과 그 방법들을 자세히 살펴보겠습니다.



### 6.2.1. 내재적 선형 모델

**내재적 선형 모델(Intrinsically Linear Models)**은 비선형 관계를 적절한 변수 변환을 통해 선형 형태로 바꾸어 회귀분석을 수행하는 방법입니다. 이렇게 변환된 변수를 사용하면 복잡한 비선형 관계도 선형 회귀분석으로 다룰 수 있어, 데이터를 더 직관적이고 효과적으로 설명할 수 있습니다. 이를 통해 예측의 정확성을 높일 수 있으며, 복잡한 패턴을 단순화하여 모델의 해석 가능성을 높이는 장점이 있습니다. 비선형 함수를 적절한 변환을 통해 직선으로 표현할 수 있는 경우, 비선형 관계를 내재적으로 선형이라고 부를 수 있습니다. 여기서는 몇 가지 대표적인 함수 변환을 설명합니다.

- **제곱 함수**

데이터가 제곱에 따라 변동하는 경우, 이를 선형적으로 다루기 위해 $X^2$ 변수를 도입할 수 있습니다. 예를 들어:

$$
Y = \beta_0 + \beta_1 X^2 + \varepsilon
$$
를 살펴봅시다.

이때 $Z = X^2$로 치환하면, 다음과 같은 선형 회귀 모델로 변환할 수 있습니다:

$$
Y = \beta_0 + \beta_1Z + \varepsilon
$$

이 변환을 통해 비선형 관계를 단순화하여 선형 회귀로 처리할 수 있습니다.

- **역수 함수**

데이터가 역수 관계를 가질 때, 이를 선형적으로 다루기 위해 다음과 같은 변환을 사용할 수 있습니다:

$$
Y = \beta_0 + \beta_1 \left(\frac{1}{X}\right) + \varepsilon
$$

여기서 $Z = \frac{1}{X}$로 치환하면 선형 회귀로 변환할 수 있습니다:

$$
Y = \beta_0 + \beta_1 Z + \varepsilon
$$

역수 변환은 급격히 감소하는 관계를 선형적으로 다루는 데 유용합니다.

- **지수 함수**

지수적 증가를 보이는 데이터를 선형 회귀로 변환하려면 다음과 같이 로그 변환을 적용할 수 있습니다. 예를 들어:

$$
Y = \beta_0 X^{\beta_1} \varepsilon
$$
를 살펴봅시다.

이 식의 양변에 로그를 취하면 다음과 같은 선형 회귀로 변환할 수 있습니다:

$$
\text{ln} Y = \ln \beta_0 + \beta_1 \ln X + \ln \varepsilon
$$

이를 통해 지수적 관계를 선형 형태로 다룰 수 있습니다. 

이번엔 다음과 같은 함수를 살펴봅시다:

$$
Y = \beta_0 e^{\beta_1 X} \varepsilon
$$

양변에 로그를 취하면 지수 함수를 선형 회귀로 변환할 수 있습니다:

$$
\text{ln} Y = \ln \beta_0 + \beta_1 X + \ln \varepsilon
$$

이렇게 하면 지수적 관계를 선형 회귀 모델로 다룰 수 있습니다. 이 방법은 급격한 증가나 감소를 보이는 데이터를 분석할 때 유용합니다.

- **로그 함수**

로그 변환은 데이터의 변동성을 안정화하고, 비선형 관계를 선형적으로 변환하는 데 사용됩니다. 예를 들어, 다음과 같은 관계를 고려할 수 있습니다:

$$
Y= \beta_0 + \beta_1 \ln X + \varepsilon
$$

이 관계에서 $Z = \ln X$로 치환하면 다음과 같은 선형 회귀식을 얻게 됩니다.

$$
Y = \beta_0 + \beta_1 Z + \varepsilon
$$

로그 변환은 특히 데이터의 분포가 매우 넓거나, 비대칭적일 때 사용하여 예측 성능을 향상시킬 수 있습니다.

- **푸리에 시리즈**

**푸리에 시리즈(Fourier Series)**는 주기적인 변동을 모델링하는 데 매우 유용한 방법입니다. 특히, 계절성을 가진 시계열 데이터에서는 주기적인 패턴을 정확하게 예측하기 위해 주기적 특성을 변수로 포함하는 것이 필수적입니다. 푸리에 시리즈를 사용하면 주기적인 변동을 사인(Sine)과 코사인(Cosine) 함수의 조합으로 표현하여 회귀분석에 적용할 수 있습니다. 이를 통해 주기적 변동을 수치적으로 표현할 수 있으며, 주기성이 있는 시계열 데이터에서 주기적 성분을 효과적으로 반영할 수 있습니다. 푸리에 시리즈는 다음과 같이 표현됩니다:
$$
s_k(t) = \sin(2πkt/m),~~ c_k(t) = \cos(2πkt/m)
$$

이때 $m$은 주기성을 나타내는 변수로, 시간 주기를 결정합니다. 이를 이용한 회귀 모델은 다음과 같이 표현됩니다:

$$
y_t = a + bt + \sum_{k=1}^K [\alpha_k s_k(t) + \beta_k c_k(t)] + \varepsilon_t 
$$

이 식에서 $a$는 상수 항, $bt$는 선형 추세, $\alpha_k$와 $\beta_k$는 주기적 변동을 설명하는 계수입니다. $K$는 주기적 성분의 복잡성을 결정하며, 주로 AIC(Akaike Information Criterion) 또는 BIC(Bayesian Information Criterion) 같은 정보기준을 최소화하는 방식으로 선택됩니다. 조화 회귀를 사용하면 주기적 패턴을 정확하게 모델링할 수 있으며, 이는 계절성을 반영하는 시계열 데이터에서 특히 유용합니다. 이를 통해 시간 흐름에 따른 주기적인 패턴을 효과적으로 분석하고, 예측 모델에 반영할 수 있습니다.

------

**예제 6-4. 푸리에 변환 예시** 

**호주 소매 판매량 데이터 푸리에 변환** <span style="color:red">(데이터, 그래프, 설명 변경 필요)</span>

다음 그래프는 호주 소매 판매량 데이터를 푸리에 시리즈를 이용하여 예측한 결과를 시각화한 그래프입니다.

![fourier](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-4.fourier.png?raw=true)

[그림 6-4: 호주 소매 판매 데이터의 푸리에 변환 차수 $K$에 따른 실제 값(검정색), 적합 값(빨간색), 미래 예측(파란색) 비교]



위 그래프는 푸리에(Fourier) 변환을 이용하여 시계열 데이터를 예측한 결과를 보여줍니다. 각 서브플롯에서 푸리에 변환의 차수 $K$를 다르게 설정하여 실제 값(검정색 선)과 예측 값(빨간색 선), 그리고 미래 예측(파란색 선)을 비교하고 있습니다. 위 그래프의 가로축은 1982년부터 1996년까지의 기간을 나타내며, 세로축은 호주 소매 판매량을 표시합니다. 각 서브플롯의 제목에는 푸리에 시리즈의 차수 $K$가 기재되어 있습니다. 차수 $K$가 1부터 6까지 다양하게 설정되어 있습니다.

그래프에서 차수 $K$는 푸리에 시리즈에 사용된 사인 및 코사인 항의 개수를 나타냅니다. 즉, $K$가 클수록 더 많은 주기적 성분을 포함하여 데이터를 모델링합니다.각 그래프를 살펴보면, 우선 차수가 1인 경우, 예측 곡선(빨간색 선)은 데이터의 전반적인 추세를 대략적으로 따라가지만, 세부적인 변동을 거의 반영하지 못하고 있습니다. 단순한 선형 형태에 가깝습니다. 차수가 2인 경우는 푸리에 변환의 차수가 증가하면서 예측 곡선이 더 구체적인 형태를 나타내기 시작합니다. 하지만 여전히 세부 변동을 제대로 반영하지 못하고 있습니다. 차수가 3인 경우, $K$ 값이 증가하면서 더 복잡한 주기적 변동이 반영되어, 실제 데이터와 예측 곡선 사이의 오차가 줄어들고 있습니다. 차수가 4인 경우에서는 세부적인 변동까지 더 많이 반영되어 실제 데이터와 예측값이 더 잘 맞아떨어집니다. 더 높은 차수에서 예측값은 실제 데이터의 패턴을 더욱 잘 따릅니다. 하지만 차수가 커질수록 모델이 복잡해지며 과적합(Overfitting)의 위험이 존재할 수 있습니다.

아래는 위 그래프를 구현하기 위한 코드입니다.

```python
#필요한 패키지 불러오기
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.api import OLS
from statsmodels.tsa.stattools import acf


#데이터 전처리
aus_retail = pd.read_csv("https://raw.githubusercontent.com/safeai-snu/Econometrics/refs/heads/main/Part.3/data/aus_retail.csv")
aus_retail['Month'] = pd.to_datetime(aus_retail['Month'], format='%Y %m')
comparison_date = pd.to_datetime('2015-12-12')
aus_cafe = aus_retail[(aus_retail['Industry'] == "Cafes, restaurants and catering services")&(aus_retail['Month']<= comparison_date)].copy()
aus_cafe = aus_cafe.groupby('Month')['Turnover'].sum().reset_index()
aus_cafe.set_index('Month', inplace=True)
aus_cafe.sort_index(inplace=True)
aus_cafe = aus_cafe.asfreq('MS')


#주기 P 자동 탐색
P = np.argmax(acf(np.log(aus_cafe["Turnover"]).dropna(), nlags=24))
if P == 0:
    P = 12 
print(f"Detected Periodicity (P): {P} months")


#푸리에 변환 특성 생성 함수
def create_fourier_features(t, P, K):
    X = np.ones((len(t), 2*K+2))
    X[:, -1] = t
    for k in range(1, K+1):
        X[:, 2*k-1] = np.sin(2 * np.pi * k * t / P)
        X[:, 2*k] = np.cos(2 * np.pi * k * t / P)
    return X


#푸리에 변환
def fit_fourier_series(df, K, P):
    
    df = df.copy()
    dt = df[:-48].copy()

    t = np.arange(len(dt))
    X = create_fourier_features(t, P, K)
    y = np.log(dt["Turnover"])  
    model = OLS(y, X).fit()
    
    dt["fitted"] = np.exp(model.predict(X)) * np.exp(y.mean() - model.predict(X).mean())

    future_t = np.arange(len(dt), len(dt) + 48)
    X_future = create_fourier_features(future_t, P, K)
    forecast = np.exp(model.predict(X_future)) * np.exp(y.mean() - model.predict(X_future).mean())
    adjustment_factor = dt["fitted"].iloc[-1] / forecast[0]
    forecast_adjusted = forecast * adjustment_factor

    future_dates = pd.date_range(dt.index[-1] + pd.DateOffset(months=1), periods=48, freq='M')
    
    return dt, forecast_adjusted, future_dates


#시각화
fig, axes = plt.subplots(3, 2, figsize=(15, 10))
axes = axes.flatten()

for i, K in enumerate(range(1, 7)):  
    modified_df, forecast, future_dates = fit_fourier_series(aus_cafe, K, P)

    ax = axes[i]
    ax.plot(aus_cafe.index, aus_cafe['Turnover'], label='Actual', color='black')
    ax.plot(modified_df.index, modified_df['fitted'], label=f'Fourier(K={K})', color='red', linestyle="dashed")
    ax.plot(future_dates, forecast, label='Forecast', color='blue', linestyle="dotted")

    ax.set_title(f'Fourier Transform Prediction (K={K})')
    ax.legend()
    ax.set_xlabel("Date")
    ax.set_ylabel("Turnover")

plt.tight_layout()
plt.show()
```

------



### 6.2.2. 추세 모델링 및 예측

이번 소단원에서는 시계열 데이터의 일관된 시간 변화 패턴을 예측하는 데 중요한 추세 모델링 기법에 대해 다룹니다. 추세는 데이터의 장기적인 변동을 반영하며, 이러한 패턴을 모델링하고 예측하는 것은 미래 데이터를 예상하는 데 있어 중요한 단계입니다. 추세 모델링에는 다양한 함수 형태가 사용될 수 있으며, 이를 통해 데이터의 성격에 맞는 최적의 추세 모델을 선택할 수 있습니다.



#### 1) 추세 모델링 $T_t$

시계열 데이터에서 추세 변수는 시간이 지남에 따라 나타나는 일관된 변화를 포착하는 핵심 요소로, 데이터의 장기적인 변동을 반영하여 미래 예측을 가능하게 합니다. 추세 모델링에서는 주로 선형, 이차 함수, 지수 함수, 로그 선형 함수 등이 사용되며, 각각의 모델은 데이터의 특성에 맞는 적절한 추세를 설명합니다.

- **선형 추세 모델**

가장 간단한 형태의 추세 모델로, 시간에 비례하여 일정하게 변화하는 패턴을 설명합니다. 선형 추세 모델은 다음과 같이 표현됩니다:

$$
T_t = \beta_0 + \beta_1 t
$$

여기서 $ \beta_0$는 절편을 나타내고, $ \beta_1$는 시간 변화에 따른 기울기(변화율)로, 시간에 비례한 일관된 증가 또는 감소를 설명합니다. 선형 추세는 경제나 사회적 현상에서 장기적인 증가 또는 감소 패턴을 나타내는 데 자주 사용됩니다.

- **이차 추세 모델**

시간이 지남에 따라 변화 속도가 가속화되거나 감속화되는 비선형적 변화를 설명하는 이차 추세 모델은 다음과 같은 형태로 나타낼 수 있습니다:

$$
T_t = \beta_0 + \beta_1 t + \beta_2 t^2
$$

이 모델에서는 $ \beta_2$가 시간의 제곱에 따른 영향을 반영합니다. 예를 들어, 가속화되는 성장이 관찰되는 경우 이러한 모델이 유용합니다.

- **지수적 추세 모델**

시간에 따라 변화율이 일정한 비율로 증가하는 경우 지수적 추세 모델이 적합합니다. 이는 다음과 같이 표현됩니다:

$$
T_t = \beta_0 e^{\beta_1 t}
$$

이 모델은 주로 인구 성장, 경제 성장 등에서 지수적으로 증가하는 패턴을 설명할 때 유용합니다.

- **로그 선형 추세 모델**

지수적 변화를 선형 관계로 표현할 수 있도록 로그 변환을 적용하는 로그 선형 추세 모델은 다음과 같습니다:

$$
\text{ln}~ T_t = \text{ln} \beta_0 + \beta_1 t
$$

로그 선형 추세 모델은 데이터의 변동성을 줄이고, 지수적 관계를 직선으로 표현하여 해석을 더 용이하게 합니다.



#### 2) 추세 모델의 추정

모델 형태를 정의한 후에는 데이터에 맞는 최적의 파라미터 $\beta$ 들을 추정해야 합니다. 이를 위해 주로 최소자승법(Ordinary Least Squares; OLS)이 사용됩니다. 이 방법은 실제 관측값  $y_t$와 모델이 예측한 추세 값 $T_t(\beta)$ 간의 차이를 최소화하는 방향으로 파라미터를 추정합니다. 추정식은 다음과 같습니다.

$$
\hat{\beta} = \arg \min_{\beta} \sum_{t=1}^T (y_t - T_t(\beta))^2 
$$

이를 통해 실제 데이터에 가장 적합한 추세 모델을 도출하고, 이 모델을 기반으로 예측을 수행할 수 있습니다.



#### 3) 추세 예측

추세 모델이 적합된 후, 이를 사용하여 미래의 값을 예측할 수 있습니다. 이는 예측하고자 하는 시점의 시간 값을 모델에 대입하여 예측값을 계산하는 방식으로 이루어집니다. 기본적인 예측 모델은 다음과 같습니다:

$$
y_t = \beta_0 + \beta_1 t + \varepsilon_t, \quad \varepsilon_t  \overset{i.i.d}{\sim} \mathcal{N}(0,\sigma^2)
$$

여기서 $\varepsilon_t$는 예측값에 포함된 랜덤한 오차로, 정규분포를 따릅니다. 예측하고자 하는 시점까지의 시간 변수를 대입하여 $h$단계 후 예측값을 계산할 수 있으며, 그 식은 다음과 같습니다:

$$
\hat{y}_{T+h |T} = \hat{\beta_0} + \hat{\beta_1} (T+h)
$$

**밀도 예측**은 단일 예측값뿐만 아니라 예측의 불확실성까지 반영하여 **예측 구간(Prediction Interval)**을 제공합니다. 예측 구간은 특정 신뢰 수준에서 예측값이 위치할 가능성이 높은 범위를 나타내며, 정규분포를 가정할 경우 95% 예측 구간은 다음과 같이 계산할 수 있습니다:
$$
y_{T+h|T} \pm 1.96\sigma \text\quad{or}\quad \hat{y}_{T+h|T} \pm 1.96\hat{\sigma}
$$

이는 예측 불확실성의 95%가 포함된 구간을 의미하며, 예측값 주변에 랜덤한 오차가 있을 수 있음을 보여줍니다.



#### 4) 예측 모델 선택

여러 추세 모델 중에서 가장 적합한 모델을 선택하기 위해 여러 평가 지표를 사용할 수 있습니다. 다음은 예측 성능을 평가하는 주요 지표입니다:

* **MSE(Mean Squared Error)**

예측 오차의 제곱 평균을 계산하여 오차의 크기를 나타냅니다. 값이 작을수록 예측이 더 정확함을 의미합니다.


* **$\text{R}^2$(Coefficient of Determination)**

예측 모델이 데이터 변동을 얼마나 설명하는지 나타내는 척도입니다. 1에 가까울수록 더 나은 모델입니다.


* **$adj-\text{R}^2$**

$\text{R}^2$와 유사하지만, 모델의 복잡도를 고려하여 조정된 값입니다.


* **AIC(Akaike Information Criterion)**

모델의 적합성과 복잡도를 동시에 고려하는 지표로, 값이 작을수록 좋은 모델입니다.


* **BIC(Bayesian Information Criterion):**

AIC와 비슷하지만, 더 큰 패널티를 부과하여 과적합을 방지하는 지표입니다.

------

**예제 6-5. 추세 모델링 예시** 

**소매 판매 데이터 추세 모델링** 

다음 그래프들은 소매 판매 데이터의 추세를 예측한 결과를 시각화한 그래프입니다. 첫 번째 그래프는 소매 판매 데이터를, 두 번째 그래프는 잔차를 시각화한 그래프입니다.

![trend](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-5.trend.png?raw=true)
![trend_res](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-5.trend_res.png?raw=true)

[그림 6-5. 소매 판매 데이터의 추세 모델링과 잔차]



위 두 개의 그래프는 **추세 모델링**에 대한 예시를 보여주고 있습니다. 첫 번째 그래프는 **소매 판매 데이터를 시각화한 그래프**입니다. 첫 번째 그래프의 가로축은 1992년부터 2016년까지의 시간 범위를 나타내며, 세로축은 판매량(Sales)을 표시합니다. 파란색 실선은 실제 리테일 판매 데이터를 나타내며, 주황색 점선은 지수 함수 모델을 사용해 추세를 나타냅니다. 이 모델은 시간이 지남에 따라 판매량이 지수적으로 증가한다고 가정합니다. 이 그래프는 **지수적 추세 모델**을 사용하여 실제 데이터에 맞춘 추세선을 보여줍니다. 데이터는 **장기적으로 지속적인 상승세**를 나타내며, 특히 최근의 상승세가 두드러집니다. 지수적 추세는 데이터를 따라가는 모양을 띠며, 일정 기간 이후 예상되는 판매 증가 추세를 예측할 수 있는 방식으로 모델링되었습니다. 추세 모델은 데이터의 장기적인 증가 패턴을 잘 포착했으나, 계절적 변동이나 단기적인 변동은 고려되지 않았습니다. 판매량이 지속적으로 증가하는 것을 나타내며, 지수적 모델이 해당 패턴을 잘 설명하고 있는 것으로 보입니다.

두 번째 그래프는 **잔차를 시각화한 그래프**입니다. 가로축은 마찬가지로 1992년부터 2016년까지의 시간을 나타냅니다. 세로축은 잔차, 즉 모델이 실제 값에서 얼마나 벗어났는지를 나타내며, 값은 약 -0.2에서 0.2 사이를 가집니다. 파란색 실선은 추세 모델로 예측한 값과 실제 데이터 간의 차이를 나타내는 잔차입니다. 이는 모델이 실제 데이터에 얼마나 잘 맞는지 보여줍니다. 그래프를 보면 **잔차는 시간이 지남에 따라 특정 패턴**을 보이고 있습니다. 특히 1996년 이후 잔차가 일정한 패턴을 띠고 있으며, 이는 **모델이 계절성 변동을 잘 포착하지 못했음**을 시사합니다.
추세 모델은 지수적 증가 패턴을 잘 설명하고 있지만, 데이터의 변동성은 제대로 반영되지 않았습니다. **잔차의 분포가 완벽하게 랜덤하지 않다**는 점에서, 추세 모델만으로는 데이터의 변동성을 완전히 설명할 수 없음을 알 수 있습니다. 주기적인 변동이나 계절성을 포착할 추가 모델링이 필요할 수 있습니다. 이 잔차 그래프는 추세 모델링이 장기적인 증가 패턴을 설명하는 데 유용하지만, 단기적인 패턴까지 설명하지 못하는 한계를 나타냅니다.

따라서, 이 추세 모델은 장기적인 지수적 성장 패턴을 포착하지만, 계절적 요인 또는 변동성을 고려한 추가 모델링이 필요할 수 있습니다.

아래는 위 그래프들을 구현하기 위한 코드입니다.

```python
#필요한 패키지 불러오기
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.regression.linear_model import OLS
from statsmodels.tools.tools import add_constant


#데이터 전처리
retail = pd.read_csv("https://raw.githubusercontent.com/safeai-snu/Econometrics/refs/heads/main/Part.3/data/example_retail_sales.csv")  
retail['ds'] = pd.to_datetime(retail['ds'])
retail['y'] = retail['y'].str.replace(",", "").astype(float)
start_date = retail['ds'].min()
retail['Time'] = (retail['ds'] - start_date) / np.timedelta64(1, 'm')


#모델 피팅
y = np.log(retail['y'])
X = add_constant(retail['Time'])
model = OLS(y, X).fit()


#추세 예측
retail['Fitted'] = model.predict(X)
retail['Exp_Fitted'] = np.exp(retail['Fitted'])


#시각화
plt.figure(figsize=(10, 5))
plt.plot(retail['ds'], retail['y'], label='Actual')
plt.plot(retail['ds'], retail['Exp_Fitted'], label='Fitted', linestyle='--')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.title('Retail Sales – Exponential Trend Regression')
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
residuals = y - retail['Fitted']
plt.plot(retail['ds'], residuals, label='Residuals')
plt.axhline(y=0, color='black', linestyle='--')
plt.xlabel('Date')
plt.ylabel('Residual')
plt.title('Retail Sales – Exponential Trend Residual Plot')
plt.legend()
plt.show()
```

------



### 6.2.3. 계절성 모델링 및 예측

이 소단원에서는 시계열 데이터에서 일정한 주기로 반복되는 변동을 반영하여 예측을 보다 정교하게 만드는 방법에 대해 설명합니다. 계절성 변수는 데이터에서 시간에 따라 규칙적으로 발생하는 패턴을 포착하는 중요한 요소로, 이러한 패턴을 효과적으로 모델링함으로써 예측의 정확성을 높일 수 있습니다. 계절성을 모델링하는 것은 주로 데이터의 특정 시간 구간에서 규칙적으로 나타나는 변동을 설명하고, 이를 바탕으로 미래의 값을 예측하는 데 사용됩니다.



#### 1) 계절성 모델링 $S_t$

계절성을 모델링하는 과정에서는 **더미 변수(One-Hot 인코딩)**와 같은 기법을 통해 각 시간 구간에서 나타나는 계절적 요인을 반영합니다. 계절성은 주로 월별, 분기별, 또는 연간 데이터를 다룰 때 중요하게 고려되며, 데이터에서 주기적으로 발생하는 변동을 설명하는 데 유용합니다. 계절성 모델은 각 시간 구간에서의 주기적인 변동을 나타내기 위해 더미 변수를 활용하여 다음과 같이 설정할 수 있습니다. 예를 들어, 월별 데이터를 분석할 때 각 월을 더미 변수로 나타낼 수 있으며, 이는 다음과 같은 형태로 표현됩니다:

$$
d_1 = (1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …)
$$
$$
d_2 = (0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, …)
$$
$$
d_3 = (0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, …)
$$
$$
d_4 = (0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, …)
$$

이 더미 변수들은 특정 주기(예: 월별, 분기별 등)마다 값을 가지며, 해당 구간의 계절적 요인을 반영합니다. 계절성 성분 $S_t$는 다음과 같이 나타낼 수 있습니다:

$$
S_t=\Sigma_i^s \gamma_i d_{it}
$$

여기서 $\gamma_i$는 각 계절 더미 변수에 대한 계수를 나타내며, $d_{it}$는 해당 시간 구간에서 더미 변수가 활성화되었는지 여부를 나타냅니다. 이 계절성 성분은 반복적인 패턴을 설명하는 중요한 요소로, 이를 통해 데이터 내에서 계절적인 변동을 포착하고 반영할 수 있습니다.



#### 2) 계절 모델 추정

계절성 요소와 시간 요소를 모두 고려하여 회귀 모델을 설정하고, 이를 통해 추세와 계절적 변동을 반영하는 모델을 추정할 수 있습니다. 계절 모델 추정은 추세와 계절적 변동을 함께 설명할 수 있는 회귀 모델을 통해 이루어지며, 다음과 같은 형태로 표현될 수 있습니다:

$$
y_t = \beta_1 t + \Sigma_i^s \gamma_i d_{it} + \varepsilon_t,  \quad \varepsilon_t \overset{i.i.d}{\sim} \mathcal{N}(0,\sigma^2)
$$

여기서 $y_t$는 예측하고자 하는 값이며, $\beta_1 t$는 시간에 따른 추세, $\Sigma_i^s \gamma_i d_{it}$는 계절성을 나타내는 더미 변수의 조합입니다. $\varepsilon_t$는 정규 분포를 따르는 오차 항으로, 모델의 예측 오차를 나타냅니다.

이 모델은 시간에 따른 변화와 계절적 변동을 모두 반영하여 데이터의 패턴을 더욱 정확하게 설명할 수 있습니다. 또한, 더미 변수를 사용함으로써 데이터의 특정 주기에서 나타나는 계절적 특성을 효과적으로 모델링할 수 있습니다.



#### 3) 계절 모델 예측

계절 모델을 이용한 예측은 추정된 모델을 바탕으로 미래의 값을 예측하는 과정입니다. 이 과정에서 예측값은 추세와 계절성을 모두 반영한 형태로 나타나며, 다음과 같이 계산됩니다:

$$
y_{T+h} = \beta_1 (T+h) +  \Sigma_i^s \gamma_i d_{i,T+h} + \varepsilon_{T+h}
$$

이때 $\varepsilon_{T+h}$는 예측 오차를 나타냅니다. 실제로 예측을 수행할 때는 오차 항을 제외한 추세와 계절성 부분만을 고려하며, 이때 예측값은 다음과 같이 표현됩니다:

$$
\hat{y}_{T+h|T} = \hat{\beta}_1 (T+h) +  \Sigma_i^s \hat{\gamma}_i d_{i,T+h}
$$

즉, 계절성과 추세를 모두 반영하여 미래의 데이터를 예측할 수 있으며, 이를 통해 주기적으로 반복되는 계절성 패턴을 반영한 더 정밀한 예측이 가능합니다.

계절성을 반영한 예측 결과는 불확실성도 함께 제공됩니다. 밀도 예측은 예측값에 대한 신뢰 구간을 제공하며, 예측의 불확실성을 함께 고려하는 방식입니다. 예측값 주변의 분포를 정규 분포 즉, $\mathcal{N}(y_{T+h|T}, \sigma)$ 또는 $\mathcal{N}(\hat{y}\_{T+h|T}, \hat{\sigma})$로 가정하여 예측 구간을 설정할 수 있으며, $y_{T+h|T} \pm 1.96\sigma$와 같은 방식으로 95% 신뢰 구간을 나타낼 수 있습니다. 이때 $\sigma$는 예측 오차의 표준편차를 나타내며, 이를 통해 예측값이 특정 구간 내에 있을 확률을 계산할 수 있습니다. 이 과정은 예측 결과에 대한 신뢰도를 높이고, 예측의 불확실성을 반영한 결과를 제공합니다.



#### 4) 예측 모델 선택

계절성 모델의 성능을 평가하기 위해서는 여러 기준을 사용할 수 있습니다. 대표적인 모델 선택 기준으로는 MSE(Mean Squared Error), R2, adj-R2, AIC(Akaike Information Criterion), BIC(Bayesian Information Criterion) 등이 있습니다. 이러한 지표를 통해 가장 적합한 예측 모델을 선택할 수 있으며, 계절성 변수의 중요성을 평가할 수 있습니다. 계절성 모델링은 특히 월별, 분기별 또는 연간 데이터를 다룰 때 매우 유용하며, 이를 통해 시간에 따른 반복적인 패턴을 더 정확하게 반영한 예측을 할 수 있습니다.

------

**예제 6-6. 계절성 모델링 예시** 

**1) 호주 맥주 판매량 데이터 시계열 분해** <span style="color:red">(데이터, 그래프, 설명 변경 필요)</span>

다음 그래프는 호주의 맥주 판매량 데이터를 분해한 결과를 시각화한 그래프입니다.

![aus-decom](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-6.aus_decomp.png?raw=true)

[그림 6-6. 호주 맥주 판매 데이터 시계열 분해 시각화]



위 그래프는 시계열 데이터를 추세(Trend), 계절성(Seasonal), 잔차(Residual)로 나눈 결과를 보여줍니다. 각 부분에 대해 분석해보겠습니다. 상단의 그래프는 실제 관측된 맥주 판매량입니다. 1970년대 초부터 2010년대까지의 데이터가 포함되어 있으며, 전반적으로 증가하다가 약간 감소하거나 안정화되는 경향을 보입니다. 계절적 변동이 뚜렷하며, 반복적인 패턴이 확인됩니다. 추세 그래프는 시간에 따른 맥주 판매량의 장기적인 방향을 나타냅니다. 초기에는 증가 추세를 보이다가, 1990년대 이후에는 약간 평평해지며, 판매량이 안정되거나 감소하는 추세가 나타납니다. 이는 외부 요인, 예를 들어 경제적 상황 변화나 소비자 선호도 변화 등의 영향을 반영할 수 있습니다. 계절성 그래프는 매년 반복되는 주기적인 패턴을 나타냅니다. 계절적인 변동이 매우 규칙적이며, 반복 주기가 일정함을 알 수 있습니다. 이 계절성은 아마도 여름철 맥주 소비량이 증가하고 겨울철에 감소하는 경향을 반영한 것으로 보입니다. 주기적인 상승과 하락이 매년 거의 같은 시점에서 발생합니다. 잔차는 추세와 계절성을 제거한 후 남은 변동을 나타냅니다. 이 부분은 예측하기 어려운 불규칙한 변동을 의미합니다. 잔차가 시간에 따라 큰 변화를 보이지 않으며, 비교적 랜덤하게 분포되어 있는 것을 볼 수 있습니다. 이는 모델이 추세와 계절성을 잘 설명했다는 것을 의미할 수 있습니다.



**2) 호주 맥주 판매량 데이터 SARIMA 잔차 분석 **<span style="color:red">(데이터, 그래프, 설명 변경 필요)</span>

다음 그래프들은 SARIMA 모델로 피팅 후 잔차를 분석한 결과를 시각화한 그래프입니다. 첫번째 그래프는 잔차를 시각화한 그래프이고, 두번째 그래프는 잔차의 자기상관계수를 시각화한 그래프입니다. 마지막 그래프는 잔차를 히스토그램으로 시각화한 그래프입니다.

![aus_res](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-7.aus_res.png?raw=true)
![aus_res_acf](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-7.aus_res_acf.png?raw=true)
![aus_res_hist](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-7.aus_res_his.png?raw=true)

[그림 6-7: 호주 맥주 판매량 데이터 SARIMA 모델 적합 후 잔차 분석]



첫번째 그래프는 SARIMA 모델에서 예측된 값과 실제 값의 차이(잔차)를 시간 축에 따라 시각화한 것입니다. SARIMA 모델이 데이터를 얼마나 잘 설명하는지 잔차의 시간적 패턴을 통해 확인할 수 있습니다. 이상적으로, 잔차는 시간에 따라 랜덤하게 변동해야 하며, 특정한 패턴을 보이지 않아야 합니다. 그래프에서 보면 대부분의 잔차가 0을 중심으로 랜덤하게 분포되어 있으며, 큰 이상치나 일정한 패턴, 추세가 보이지 않습니다. 이는 모델이 데이터를 잘 적합시켰다는 것을 의미합니다. 다만, 초반부의 몇몇 큰 잔차가 눈에 띄며, 이는 모델이 초기에 일부 관측값에 대해 큰 예측 오류를 일으켰음을 나타냅니다. 이를 보완하기 위해 추가적인 모델링 개선이 필요할 수 있습니다. 잔차가 균등하게 분포하고 있다는 것은 모델이 데이터에 과적합되지 않았다는 것을 암시하며, 모델의 안정성을 확인할 수 있습니다.

두번째 그래프는 ACF 그래프로 잔차들 간의 자기상관성을 나타냅니다. SARIMA 모델의 잔차들이 무작위적으로 분포되었는지 확인하는 중요한 도구입니다. 잔차가 무작위적일 경우, 지연 간격에 따른 상관계수는 0에 가까워야 합니다. 그래프에서 지연 간격 0을 제외한 대부분의 시차에서 상관계수가 0에 가깝게 분포되어 있는 것을 볼 수 있습니다. 이는 잔차들 간에 자기상관성이 거의 없음을 나타내며, SARIMA 모델이 데이터를 잘 설명하고 있다는 것을 시사합니다. 첫 번째 지연 간격에서 약간의 자기상관성이 보일 수 있지만, 이는 통계적으로 큰 문제가 없을 가능성이 큽니다.

세번째 그래프는 잔차에 대한 히스토그램으로 SARIMA 모델에서 얻어진 잔차들의 분포를 나타냅니다. 히스토그램 위에 그려진 커브는 잔차 분포의 추정 밀도입니다. 잔차 분포가 정규 분포와 일치하는지 시각적으로 확인할 수 있습니다. 그래프에서 대부분의 잔차는 0을 중심으로 대칭적으로 분포되어 있으며, 이는 모델이 잔차를 비교적 잘 처리했음을 시사합니다. 잔차의 중심이 0에 가까운 것은 모델의 편향이 거의 없음을 의미합니다. 다만, 그래프에서 극단적인 값이 일부 존재하는데, 이는 이상치나 예측 오류의 가능성을 나타낼 수 있습니다.

종합적으로, SARIMA 모델이 대체로 데이터를 잘 설명하고 있으며, 잔차가 대부분 무작위적으로 분포되어 있음을 알 수 있습니다.



**3) 호주 맥주 판매량 데이터 SARIMA 예측** <span style="color:red">(데이터, 그래프, 설명 변경 필요)</span>

다음 그래프들은 SARIMA 모델로 분석한 결과를 시각화한 그래프입니다. 첫번째 그래프는 모델 피팅 값을 시각화 그래프이고, 두번째 그래프는 모델을 이용한 예측값을 시각화한 그래프입니다.

![aus_fit](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-8.aus_fit.png?raw=true)
![aus_pred](https://github.com/safeai-snu/Econometrics/blob/main/Part.3/figures/6-8.aus_pred.png?raw=true)

[그림 6-8. 호주 맥주 판매량 데이터 SARIMA 모델 적합 후 예측 결과]



첫번째 그래프는 실제 값과 계절성 모델을 사용해 추정된 피팅 값의 비교를 보여줍니다. 가로축은 실제 값이고 세로축은 모델에서 예측한 값입니다. 관찰 결과, 대부분의 점들이 대각선 방향으로 배열되어 있어, 예측된 값이 실제 값에 가까운 경향을 보임을 알 수 있습니다. 이상치로 보이는 몇몇 점들을 제외하고, 전체적인 예측 성능은 양호하다고 볼 수 있습니다. 이 그래프는 모델의 적합성을 평가하는 데 유용하며, 대체로 예측 값이 실제 값과 일치하는 경향이 있음을 나타냅니다. 하지만 몇몇 데이터 포인트는 실제 값보다 더 높은 오차를 보이고 있어 추가적인 검토가 필요할 수 있습니다.

두 번째 그래프는 맥주 생산량에 대한 예측 결과를 시각화한 것입니다. 빨간색으로 표시된 실제 데이터와 파란색으로 표시된 예측 데이터가 겹치는 부분에서 모델이 데이터를 얼마나 잘 예측했는지 볼 수 있습니다. 특히 이 그래프는 예측 구간을 포함하여 모델이 제시하는 미래의 값에 대한 불확실성도 시각화하였습니다. 실제 데이터와 예측된 데이터는 전반적으로 비슷한 패턴을 따르지만, 예측 구간이 넓어짐에 따라 모델의 신뢰도가 점점 낮아지는 것을 알 수 있습니다. 이는 계절성 요소가 뚜렷한 데이터에 대해 적절히 대응했음을 보여주며, 예측 구간이 좁을수록 모델의 신뢰도가 더 높음을 시사합니다.

이 두 그래프는 계절성 모델링의 강력한 예측 성능을 보여주며, 특히 주기적으로 발생하는 패턴을 반영한 계절적 요소를 고려한 예측 모델이 효과적임을 강조하고 있습니다.

아래는 위 그래프들을 구현하기 위한 코드입니다.

```python
#필요한 패키지 불러오기
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.graphics.tsaplots import plot_acf
import matplotlib.dates as mdates


#데이터 불러오기
aus_beer = pd.read_csv('https://raw.githubusercontent.com/safeai-snu/Econometrics/refs/heads/main/Part.3/data/aus_production.csv', parse_dates=['Quarter'], index_col='Quarter')


#시계열 분해
decomposition = seasonal_decompose(aus_beer['Beer'], model='additive', period=4)


#분해 시각화
fig, ax = plt.subplots(4, 1, figsize=(10, 8))

ax[0].plot(decomposition.observed)
ax[0].set_title('Observed', fontsize=12)
ax[0].set_ylabel('Value')

ax[1].plot(decomposition.trend)
ax[1].set_title('Trend', fontsize=12)
ax[1].set_ylabel('Value')

ax[2].plot(decomposition.seasonal)
ax[2].set_title('Seasonal', fontsize=12)
ax[2].set_ylabel('Value')

ax[3].scatter(aus_beer.index, decomposition.resid, alpha=0.5)
ax[3].set_title('Residual', fontsize=12)
ax[3].set_ylabel('Value')

ax[0].xaxis.set_major_locator(mdates.YearLocator())
ax[1].xaxis.set_major_locator(mdates.YearLocator())
ax[2].xaxis.set_major_locator(mdates.YearLocator())
ax[3].xaxis.set_major_locator(mdates.YearLocator())

ax[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
ax[2].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
ax[3].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))

for axis in ax:
    plt.setp(axis.get_xticklabels(), rotation=45, ha='right')

plt.tight_layout()
plt.show()


#계절성 더미 변수 추가
aus_beer_dummies = pd.get_dummies(aus_beer.index).T


#모델 피팅 (더미 변수 추가)
sarima_model = SARIMAX(aus_beer['Beer'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 4), exog=aus_beer_dummies)
sarima_results = sarima_model.fit()
residuals = sarima_results.resid


#잔차 시각화
plt.figure(figsize=(20, 8))
plt.plot(residuals)
plt.title('Residuals from SARIMA Model')
plt.show()

plt.figure(figsize=(20, 8))
plot_acf(residuals, lags=40)
plt.show()

plt.figure(figsize=(20, 8))
sns.histplot(residuals, bins=20, kde=True)
plt.title('Histogram of Residuals')
plt.show()


#모델 시각화
fitted_values = sarima_results.fittedvalues
plt.figure(figsize=(20, 8))
sns.scatterplot(x=aus_beer['Beer'], y=fitted_values)
plt.xlabel('Actual Values')
plt.ylabel('Fitted Values')
plt.title('Actual vs Fitted Values')
plt.show()


#예측 시각화
forecast = sarima_results.get_forecast(steps=8, exog=aus_beer_dummies.iloc[-8:])
forecast_ci = forecast.conf_int()

plt.figure(figsize=(20, 8))
plt.plot(aus_beer.index, aus_beer['Beer'], label='Actual', color='red')
plt.plot(forecast_ci.index, forecast.predicted_mean, label='Forecast')
plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='lightgrey', alpha=0.5)
plt.title('Beer Production Forecast')
plt.legend()
plt.show()
```

------



------

 **각주**           

[^Box and Pierce (1970)]: [Box and Pierce (1970)] Box, G.E.P. and Pierce, D.A. (1970) Distribution of Residual Autocorrelations in Autoregressive Integrated Moving Average Time Series Models. Journal of the American Statistical Association, 65, 1509-1526. 
[^Diebold. (2017)]: [Diebold. (2017)] F. X. Diebold, Forecasting in Economics, Business, Finance and Beyond.
[https://www.sas.upenn.edu/~fdiebold/Teaching221/Forecasting.pdf](https://www.sas.upenn.edu/~fdiebold/Teaching221/Forecasting.pdf)
[^Diebold. (2019)]: [Diebold. (2019)]   F. X. Diebold, Econometric Data Science: A Predictive Modeling Approach.
[https://www.sas.upenn.edu/~fdiebold/Teaching104/Econometrics.pdf](https://www.sas.upenn.edu/~fdiebold/Teaching104/Econometrics.pdf)

[^Diebold. (2019)]: [Diebold. (2019)] F. X. Diebold, Time-Series Econometrics. A Concise Course.
[https://www.sas.upenn.edu/~fdiebold/Teaching706/TimeSeriesEconometrics.pdf](https://www.sas.upenn.edu/~fdiebold/Teaching706/TimeSeriesEconometrics.pdf)
[^Gasthaus (2021)]: [Gasthaus (2021)] J Gasthaus et al., Modern Aspects of Big Time Series Forecasting, IJCAI 2021
[https://lovvge.github.io/Forecasting-Tutorial-IJCAI-2021/](https://lovvge.github.io/Forecasting-Tutorial-IJCAI-2021/)

[^Gneiting et al. (2007)]: [Gneiting et al. (2007)] Gneiting, T., Balabdaoui, F., & Raftery, A. E. (2007). Probabilistic forecasts, calibration and sharpness. *Journal of the Royal Statistical Society Series B: Statistical Methodology*, *69*(2), 243-268.
[^Hyndman (2021)]: [Hyndman (2021)] R. J Hyndman and G. Athanasopoulos, Forecasting: Principles and Practice-3rd Ed.
[^Joseph. (2022)]: [Joseph. (2022)] M. Joseph, Modern Time Series Forecasting with Python.
[^Ljung-Box (1978)]: [Ljung-Box (1978)]  M. Ljung; G. E. P. Box (1978). "On a Measure of a Lack of Fit in Time Series Models". *[Biometrika](https://en.wikipedia.org/wiki/Biometrika)*. **65** (2): 297–303.
[^Tsay. (2010)]: [Tsay. (2010)] R. S. Tsay, Analysis of Financial Time Series-3rd Ed.
[^Newsvendor]: https://en.wikipedia.org/wiki/Newsvendor_model

[^CRSP]: https://www.lokad.com/continuous-ranked-probability-score/
[^fpp3]: https://cran.r-project.org/web/packages/fpp3/index.html


이 책은 서울대학교 미래기초학문분야기반조성사업의 지원을 받아 제작되었습니다.

Copyright © 2024 Seoul National University

ALL RIGHTS RESERVED. No part of this work covered by the copyright herein may be reproduced, transmitted, stored or used in any form or by any means graphic, electronic, or mechanical, including but not limited to photocopying, recording, scanning, digitizing, taping, Web distribution, information networks, or information storage and retrieval systems without the prior written permission of the author.
